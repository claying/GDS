title: Data Processing, Pattern computation
data: 2016-04-04
category: notes
tags: data processing, k-mer, notes

Based on the kernel methods, the problem of generic determinants selection can be formulated as following:
$$\min_{\beta\in\mathbb R^{p}}\frac{1}{n}\sum_{i=1}^{n}L\left(Y_i, \phi_i \cdot \beta\right)+\lambda \Omega(\beta)$$
where $L$ is a loss function and $\Omega$ is a regularization function.
The vector $\phi_i$ is a feature vector obtained by mapping the sequence $i$ to the Hilbert space $\mathbb R^p$.

There are different choices of the mapping function:
- spectrum kernel: $\phi_i$ denote the vector of the number of occurrences of each present k-mer.
- substring kernel

In all cases, the kernel function is supposed to be a comparison function or a similarity measure, and $\phi$ is a mapping projecting original space to a more easily comparable space.

Our first approach is to apply spectrum kernel for k-mers of different lengths. To have a straightforward feeling of the presence of k-mers of different lengths, we can also display some visualization using these feature matrices.

## Computing features matrices
