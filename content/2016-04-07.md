title: Preprocessing, Ridge Regression
data: 2016-04-07
category: notes
tags: ridge regression, preprocessing, notes

In a first stage, I applied the ridge regression to the problem in order to get a benchmark. More precisely, the original problem can be reformulated:

$$\min_{\beta\in\mathbb R^{p}}\frac{1}{2}\left\|Y- \phi \cdot \beta\right\|_2^2+\frac{\lambda}{2} \|\beta\|_2^2$$

where the loss function has been replaced by the square loss and the regularization function has been replaced by the $\ell_2$ norm.

This problem has already been extensively studied and there are various approaches to resolve it, such as the reformulation with kernel matrix, proximal method with gradient descent. Before applying these optimization methods, we need to preprocess the data in order to reduce the predictor sensibilities and the impact of data skewness or outliers.

## Preprocessing
Transformations of training set data may significantly improve the performance of the prediction. And there different ways and strategies to transform $Y$ and $\phi$.

According to the book **Applied Predictive Modeling** (Max Kuhn, Kjell Johnson 2013), The principal transformation methods are centering, scaling and skewness resolution.

#### Outcome variable $Y$
For the vector $Y$, since it is the outcome variable representing the strength of replication, we need the transformation to be reversible or at least monotone. By consequence, we consider especially the transformations resolving skewness. The formulae for the sample skewness statistic is defined:

$$skewness=\frac{\sum (Y_i-\overline Y)^3}{(n-1)v^{3/2}}$$

where $v=\frac{\sum (Y_i-\overline Y)^2}{n-1}$. An un-skewed distribution is one that is roughly symmetric. To reduce the skewness, we can apply a class of transformations proposed by Box and Cox with a parameter $\lambda$:

$$Y^*=
\begin{cases}
\frac{Y^{\lambda}-1}{\lambda} & \text{if } \lambda\neq 0 \\
\log(Y) & \text{if } \lambda = 0
\end{cases}
$$

I display in the following the distribution of $Y$ as well as its distribution after Box-Cox transformation.

| $\lambda$ | skewness |
| --------- | -------- |
| original  | 8.28     |
| 0         | 0.57     |
| -0.25     | 0.015    |

![distribution-of-Y]({filename}/images/preprocessing/hist_y.png)
![distribution-of-Y]({filename}/images/preprocessing/hist_log_y.png)
![distribution-of-Y]({filename}/images/preprocessing/hist_box_cox.png)

Ultimately, we could consider the following choices to transform $Y$:

* log
* log + standardization
* Box-Cox with $\lambda=-0.25$ (increasing function)

#### Feature matrix $\phi$

The reasonable transformation for the matrix $\phi$ should conserve its sparsity and prevent a bias towards longer sequences. Inspired from the statistical approaches in information retrieval (**C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 118-120**), we could consider the tf-idf weighting. Here $\text{tf}_{t,d}$ corresponds to term frequency of $t$ in document $d$ and $\text{idf}_{t}$ corresponds to inverse document frequency of term $t$. By combining the two definitions, we can produce a composite weight for each term in each document. The tf–idf weighting scheme assigns to term t a weight in document d given by

$$\text{tf-idf}_{t,d}=\text{tf}_{t,d}\times \text{idf}_d$$

<!-- * normalization $\ell_2$ along the columns by analogy for the normalization of spectrum kernel ([THE SPECTRUM KERNEL: A STRING KERNEL FOR
SVM PROTEIN CLASSIFICATION][2])
* term frequency–inverse document frequency ([tf-idf][1]) -->

tf-idf can also be seen as a numerical statistic to reflect how important a word is to a document in a collection or corpus. In our case, by analogy, we could use it to measure how important a k-mer is to a sequence. Additionally according to this book, to compensate for the effect of document length, the standard way of quantifying the similarity between documents is to compute the cosine similarity of their representation. Thus by using the same notation, i.e. if $\text{tf}_{t,d}$ denotes the raw frequency of k-mer $t$ in sequence $d$ and $\text{df}_t$ denotes the number of sequences where $t$ appears, we could consider the following weighting schemes:

term frequency | inverse document frequency | normalization
-------------- | :------------------------: | -------------
$\text{tf}_{t,d}$<br/>$1+\log(\text{tf}_{t,d})$ <br/> $1_{\text{tf}_{t,d}>0}$ (binary) | $1$<br/>$\log\frac{N}{\text{df}_t}$ | $1$ (no)<br/>$\ell_2$ |

Pratically, I eliminated the following schemes as they didn't work as well as other transformations:

* $\text{tf}_{t,d} \times 1$ without normalization
* $\text{tf}_{t,d} \times \log\frac{N}{\text{df}_t}$ without normalization

<!-- * $f_{a,s}\cdot\log\frac{N}{n_a}$
* $(1+\log f_{a,s})\cdot\log\frac{N}{n_a}$ -->

## Ridge regression and results
Since the size of kernel matrix is $70975\times 70975$, which is too expensive to inverse, I chose a fast iterative method called FISTA (fast iterative shrinkage-thresholding algorithm), implemented in the toolbox SPAMS by Julien Mairal.

#### - First Experiment
* $Y$: $\log$
* $\phi$: different schemes listed above

![ridge]({filename}/images/ridge/logY/ridge_5.png)
![ridge]({filename}/images/ridge/logY/ridge_6.png)
![ridge]({filename}/images/ridge/logY/ridge_7.png)
![ridge]({filename}/images/ridge/logY/ridge_8.png)
![ridge]({filename}/images/ridge/logY/ridge_9.png)
![ridge]({filename}/images/ridge/logY/ridge_10.png)


<!-- #### - First configuration
* $\phi$: normalization $\ell_2$ along the columns
* $Y$: log + standardization

I put this configuration at the first stage because it shows quite good prediction results.

![ridge]({filename}/images/ridge/cv_config1/normalize_5_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_6_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_7_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_8_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_9_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_10_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_11_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_12_mse.png)
![ridge]({filename}/images/ridge/cv_config1/normalize_13_mse.png) -->


[1]: https://en.wikipedia.org/wiki/Tf%E2%80%93idf
[2]: http://www.ics.uci.edu/~welling/teatimetalks/kernelclub04/spectrum.pdf
